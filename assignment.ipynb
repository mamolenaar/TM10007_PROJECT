{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiDn2Sk-VWqE",
        "outputId": "492078f8-c346-4479-eaa1-40e5d9f8c3aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/mamolenaar/TM10007_PROJECT_SvdMeijden_MMolenaar.git      #SIRI: mamolenaar moet je even aanpassen"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4ZsvmQBVuXM",
        "colab_type": "text"
      },
      "source": [
        "##Taakverdeling eindopdracht:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1.   **Datapreperatie**\n",
        "\n",
        "\n",
        "* *Verwijderen duplicaten kolommen (als aanwezig)*   DONE \n",
        "*  *Nulwaarden verwijderen* (Siri)        DONE\n",
        "* *Trainingset/validatieset* (Mitch)       DONE\n",
        "* Testing outliers with Z-score (Mitch)\n",
        "*   Scaling features (Mitch)\n",
        "* PCA?\n",
        "* Feature selection \n",
        "\n",
        "\n",
        "2.   **Random Forest**\n",
        "* Bagging/bootstrap aggregating \n",
        "* Hyperparameter tuning\n",
        "* Ensembling \n",
        "3. **Support Vector Machine**\n",
        "* Kernel\n",
        "* Hyperparameter tuning \n",
        "4. **Multilayer neural network** \n",
        "* Activation and loss function\n",
        "5. **Convolutional NN/Recurrent NN** \n",
        "(Ik weet niet zeker of we deze ook moeten toepassen) \n",
        "\n",
        "\n",
        "Checklist punten verslag / punten om overna te denken\n",
        "1. Datapreparatie\n",
        "- Hoeveel nulwaarden/NaNs zijn er? in welke kolommen komen deze voor? \n",
        "  komen er veel NaNs voor in dezelfde kolom? Zo ja, is het geoorloofd om deze kolommen te imputeren? Op welke manier imputeren (op basis van andere features (multivariate imputation) of eigen features: zie https://scikit-learn.org/stable/modules/impute.html\n",
        "\n",
        "- Imputatie: https://towardsdatascience.com/handling-missing-data-for-a-beginner-6d6f5ea53436\n",
        "\n",
        "- Hebben we veel kolommen waarin outliers zitten? Zo ja, dan moeten we hierop scaling aanpassen, zie: https://scikit-learn.org/stable/modules/preprocessing.html. Testen outliers met Z-score:https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\n",
        "\n",
        "- We nemen aan dat basic classifiers (KNN, linear, quadratic etc.) te simpel zijn om te gebruiken (toch?). Wat kan het doen van feature selection hierover zeggen?\n",
        "Als we toch basic classifiers gebruiken, moeten we hier voorafgaand PCA op toepassen?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLL0JMQodTOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######## Import packages and models ##########################################\n",
        "\n",
        "# Import general packages\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets as ds\n",
        "import seaborn\n",
        "from sklearn import model_selection\n",
        "\n",
        "\n",
        "# import classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# import models\n",
        "models = [\n",
        "    ('NB', GaussianNB()),\n",
        "    ('LDA', LinearDiscriminantAnalysis()),\n",
        "    ('QDA', QuadraticDiscriminantAnalysis()),\n",
        "    ('LR', LogisticRegression()),\n",
        "    ('SGD', SGDClassifier()),\n",
        "    ('DT', DecisionTreeClassifier()),\n",
        "    ('KNN', KNeighborsClassifier()),   #hieronder verdere modellen toevoegen\n",
        "]\n",
        "\n",
        "# Import datapreprocessing\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Import split data in train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score # allows one scoring metric\n",
        "from sklearn.model_selection import cross_validate # allows us to use multiple scoring metrics\n",
        "\n",
        "# Import metrics\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NE_fTbKGe5z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "cf871d5a-8c44-49f3-cf14-88c152711b99"
      },
      "source": [
        "# Data loading functions. \n",
        "from hn.load_data import load_data\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "data.info\n",
        "# Find labels assigned for tumor classification \n",
        "def unique(list1): \n",
        "    x = np.array(list1) \n",
        "    print(np.unique(x)) \n",
        "k=data.head()\n",
        "print(k)\n",
        "print(\"The unique labels assigned to each patient for tumor classification are\") \n",
        "unique(data['label'])\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples: 113\n",
            "The number of columns: 160\n",
            "               hf_energy  hf_entropy  ...  tf_NGTDM_Contrast  tf_NGTDM_Strength\n",
            "ID                                    ...                                      \n",
            "0_HN1006_0  24345.357124    3.444203  ...           0.000000           0.000000\n",
            "0_HN1022_0  35301.370880    2.873434  ...           0.000109           0.018735\n",
            "0_HN1026_0   6340.950214    2.769541  ...           0.000004           0.672940\n",
            "0_HN1029_0   5690.500179    3.073200  ...           0.000192           0.062940\n",
            "0_HN1046_0  15553.548185    3.025631  ...           0.000209           0.030421\n",
            "\n",
            "[5 rows x 160 columns]\n",
            "The unique labels assigned to each patient for tumor classification are\n",
            "['T12' 'T34']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdOFTFiBduX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1117dee9-d3c3-4590-d8c5-ed98145bd67e"
      },
      "source": [
        "########################## Data preperation ##########################\n",
        "\n",
        "data = data.drop(columns=\"label\")\n",
        "print(data)\n",
        "\n",
        "# Replace zero values with NaN \n",
        "data = data.replace(0, np.NaN)\n",
        "# count the number of NaN values in each column\n",
        "print(data.isnull().sum())\n",
        "\n",
        "print(data.head(20))\n",
        "\n",
        "# Select data without labels and ID\n",
        "X = np.array(data.drop(['label', 'ID'], axis=1))\n",
        "# Select label data\n",
        "y = np.array(data['label'])\n",
        "\n",
        "data = data.loc[:,~data.columns.duplicated()]   # delete duplicated columns if available\n",
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean') # impute NaN values with mean values\n",
        "\n",
        "\n",
        "#z = np.abs(stats.zscore(data))\n",
        "#print(z)\n",
        "\n",
        "\n",
        "# Select data without labels and ID\n",
        "X = np.array(data.drop(['label', 'ID'], axis=1))\n",
        "# Select label data\n",
        "y = np.array(data['label'])\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               hf_energy  hf_entropy  ...  tf_NGTDM_Contrast  tf_NGTDM_Strength\n",
            "ID                                    ...                                      \n",
            "0_HN1006_0  24345.357124    3.444203  ...       0.000000e+00           0.000000\n",
            "0_HN1022_0  35301.370880    2.873434  ...       1.090935e-04           0.018735\n",
            "0_HN1026_0   6340.950214    2.769541  ...       3.528037e-06           0.672940\n",
            "0_HN1029_0   5690.500179    3.073200  ...       1.917977e-04           0.062940\n",
            "0_HN1046_0  15553.548185    3.025631  ...       2.093031e-04           0.030421\n",
            "...                  ...         ...  ...                ...                ...\n",
            "0_HN1950_0  50004.678306    2.246432  ...       0.000000e+00           0.000000\n",
            "0_HN1954_0  58235.863884    2.554536  ...       1.381761e-06           0.137259\n",
            "0_HN1968_0  16630.150022    2.341213  ...       9.970363e-08           1.423791\n",
            "0_HN1987_0  58087.164347    2.159815  ...       5.282298e-05           0.013049\n",
            "0_HN1998_0  12724.205929    3.085224  ...       6.309797e-06           0.206874\n",
            "\n",
            "[113 rows x 159 columns]\n",
            "hf_energy               0\n",
            "hf_entropy              0\n",
            "hf_kurtosis             0\n",
            "hf_max                  0\n",
            "hf_mean                 0\n",
            "                       ..\n",
            "tf_NGTDM_Busyness      54\n",
            "tf_NGTDM_Coarseness     0\n",
            "tf_NGTDM_Complexity    54\n",
            "tf_NGTDM_Contrast      54\n",
            "tf_NGTDM_Strength      54\n",
            "Length: 159, dtype: int64\n",
            "                hf_energy  hf_entropy  ...  tf_NGTDM_Contrast  tf_NGTDM_Strength\n",
            "ID                                     ...                                      \n",
            "0_HN1006_0   24345.357124    3.444203  ...                NaN                NaN\n",
            "0_HN1022_0   35301.370880    2.873434  ...       1.090935e-04           0.018735\n",
            "0_HN1026_0    6340.950214    2.769541  ...       3.528037e-06           0.672940\n",
            "0_HN1029_0    5690.500179    3.073200  ...       1.917977e-04           0.062940\n",
            "0_HN1046_0   15553.548185    3.025631  ...       2.093031e-04           0.030421\n",
            "0_HN1047_0    1869.551078    2.727910  ...       9.252106e-05           0.348634\n",
            "0_HN1054_0   26047.660529    1.996334  ...                NaN                NaN\n",
            "0_HN1057_0   19240.426509    4.419829  ...                NaN                NaN\n",
            "0_HN1062_0    2563.752075    4.499476  ...                NaN                NaN\n",
            "0_HN1067_0   27345.498154    1.422448  ...       6.939134e-07           0.329738\n",
            "0_HN1079_0   66421.342615    3.191575  ...                NaN                NaN\n",
            "0_HN1080_0   13164.012744    2.716591  ...       3.017139e-04           0.022110\n",
            "0_HN1081_0     880.042943    3.031140  ...                NaN                NaN\n",
            "0_HN1092_0   55831.185816    3.116710  ...       4.657222e-04           0.010091\n",
            "0_HN1095_0  180898.517072    2.015360  ...       3.265702e-05           0.007767\n",
            "0_HN1096_0   48765.675314    2.743775  ...       2.341160e-05           0.023226\n",
            "0_HN1102_0   73156.929695    1.703219  ...       2.040178e-06           0.063199\n",
            "0_HN1106_0    1066.789930    3.511552  ...                NaN                NaN\n",
            "0_HN1117_0   36495.023908    1.522734  ...       1.322904e-05           0.049534\n",
            "0_HN1118_0   55376.968667    3.724121  ...                NaN                NaN\n",
            "\n",
            "[20 rows x 159 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-8458fc087f6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Select data without labels and ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# Select label data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4115\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4116\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4117\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4118\u001b[0m         )\n\u001b[1;32m   4119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3912\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3913\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3914\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3945\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3946\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5340\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not found in axis\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['label' 'ID'] not found in axis\""
          ]
        }
      ]
    }
  ]
}